{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49feaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import OpenAI\n",
    "from langchain_openai.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# client = OpenAI.Client()\n",
    "OpenAI.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = OpenAI()\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "    Responda a seguinte pergunta do usuário:\n",
    "    {pergunta}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a26453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Responda a seguinte pergunta do usuário:\n",
      "    O que é um SaaS?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(pergunta=\"O que é um SaaS?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2136272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "    Responda a seguinte pergunta do  em até {n_palavras} palavras:\n",
    "    {pergunta}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9fde00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Responda a seguinte pergunta do  em até 15 palavras:\n",
      "    O que é um SaaS?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(pergunta=\"O que é um SaaS?\", n_palavras=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f09a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "    Responda a seguinte pergunta do  em até {n_palavras} palavras:\n",
    "    {pergunta}\n",
    "\"\"\", partial_variables={\"n_palavras\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4364a97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Responda a seguinte pergunta do  em até 10 palavras:\n",
      "    O que é LangChain?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(pergunta=\"O que é LangChain?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798ecf0",
   "metadata": {},
   "source": [
    "### Utilizando Múltiplos Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e79a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template_word_count = PromptTemplate.from_template(\"\"\"\n",
    "Responda a seguinte pergunta em até {n_palavras} palavras:\n",
    "\"\"\")\n",
    "\n",
    "template_line_count = PromptTemplate.from_template(\"\"\"\n",
    "Responda a seguinte pergunta em até {n_linhas} linhas:\n",
    "\"\"\")\n",
    "\n",
    "template_idioma = PromptTemplate.from_template(\"\"\"\n",
    "Responda a resposta em {idioma}\n",
    "\"\"\")\n",
    "\n",
    "template_final = (template_word_count + template_line_count + template_idioma +\n",
    "                 \"Responda a pergunta seguindo as instruções {pergunta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341a51b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['idioma', 'n_linhas', 'n_palavras', 'pergunta'] template='\\nResponda a seguinte pergunta em até {n_palavras} palavras:\\n\\nResponda a seguinte pergunta em até {n_linhas} linhas:\\n\\nResponda a resposta em {idioma}\\nResponda a pergunta seguindo as instruções {pergunta}'\n"
     ]
    }
   ],
   "source": [
    "print(template_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ea8eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhat is the sun?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_final = template_final.format(n_palavras=10, n_linhas=1, idioma=\"Inglês\", pergunta=\"O que é o sol?\")\n",
    "llm.invoke(prompt_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aab49703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Responda a seguinte pergunta em até 10 palavras:\n",
      "\n",
      "Responda a seguinte pergunta em até 1 linhas:\n",
      "\n",
      "Responda a resposta em Inglês\n",
      "Responda a pergunta seguindo as instruções O que é o sol?\n"
     ]
    }
   ],
   "source": [
    "print(prompt_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ce941",
   "metadata": {},
   "source": [
    "### Templates para Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ccecd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Essa é minha dúvida: Quem é você?')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_template(\"Essa é minha dúvida: {duvida}\")\n",
    "chat_template.format_messages(duvida=\"Quem é você?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1780701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Você é um assistente irônico e se chama {nome_assistente}\"),\n",
    "        (\"human\", \"Olá como vai?\"),\n",
    "        (\"ai\", \"Estou bem, como posso lhe ajudar?\"),\n",
    "        (\"human\", \"{pergunta}\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2125db68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['nome_assistente', 'pergunta'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['nome_assistente'], template='Você é um assistente irônico e se chama {nome_assistente}')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Olá como vai?')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Estou bem, como posso lhe ajudar?')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pergunta'], template='{pergunta}'))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e3d3828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Você é um assistente irônico e se chama BotX'),\n",
       " HumanMessage(content='Olá como vai?'),\n",
       " AIMessage(content='Estou bem, como posso lhe ajudar?'),\n",
       " HumanMessage(content='Qual o seu nome?')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template.format_messages(nome_assistente=\"BotX\", pergunta=\"Qual o seu nome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac51071d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Meu nome é BotX, estou aqui para responder suas perguntas com um toque de ironia. Como posso te ajudar?', response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 55, 'total_tokens': 85, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c1478cb2-c056-455b-863e-b5d8f853b4a1-0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "chat.invoke(chat_template.format_messages(nome_assistente=\"BotX\", pergunta=\"Qual o seu nome?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cdf9b5",
   "metadata": {},
   "source": [
    "### Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27aea0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplos = [\n",
    "    {\n",
    "        \"pergunta\": \"Qual é a maior montanha do mundo, o Monte Everest ou o K2?\",\n",
    "        \"resposta\": \"\"\"\n",
    "São necessárias perguntas de acompanhamento aqui: Sim.\n",
    "Pergunta de acompanhamento: Qual é a altura do Monte Everest?\n",
    "Resposta intermediária: O Monte Everest tem 8.848 metros de altura.\n",
    "Pergunta de acompanhamento: Qual é a altura do K2?\n",
    "Resposta intermediária: O K2 tem 8.611 metros de altura.\n",
    "Então a resposta final é: Monte Everest\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"pergunta\": \"Quem nasceu primeiro, Charles Darwin ou Albert Einstein?\",\n",
    "        \"resposta\": \"\"\"\n",
    "São necessárias perguntas de acompanhamento aqui: Sim.\n",
    "Pergunta de acompanhamento: Quando nasceu Charles Darwin?\n",
    "Resposta intermediária: Charles Darwin nasceu em 12 de fevereiro de 1809.\n",
    "Pergunta de acompanhamento: Quando nasceu Albert Einstein?\n",
    "Resposta intermediária: Albert Einstein nasceu em 14 de março de 1879.\n",
    "Então a resposta final é: Charles Darwin\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"pergunta\": \"Quem foi o pai de Napoleão Bonaparte?\",\n",
    "        \"resposta\": \"\"\"\n",
    "São necessárias perguntas de acompanhamento aqui: Sim.\n",
    "Pergunta de acompanhamento: Quem foi Napoleão Bonaparte?\n",
    "Resposta intermediária: Napoleão Bonaparte foi um líder militar e imperador francês.\n",
    "Pergunta de acompanhamento: Quem foi o pai de Napoleão Bonaparte?\n",
    "Resposta intermediária: O pai de Napoleão Bonaparte foi Carlo Bonaparte.\n",
    "Então a resposta final é: Carlo Bonaparte\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"pergunta\": \"Os filmes 'O Senhor dos Anéis' e 'O Hobbit' foram dirigidos pelo mesmo diretor?\",\n",
    "        \"resposta\": \"\"\"\n",
    "São necessárias perguntas de acompanhamento aqui: Sim.\n",
    "Pergunta de acompanhamento: Quem dirigiu 'O Senhor dos Anéis'?\n",
    "Resposta intermediária: 'O Senhor dos Anéis' foi dirigido por Peter Jackson.\n",
    "Pergunta de acompanhamento: Quem dirigiu 'O Hobbit'?\n",
    "Resposta intermediária: 'O Hobbit' também foi dirigido por Peter Jackson.\n",
    "Então a resposta final é: Sim\n",
    "\"\"\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8e29fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"pergunta\", \"resposta\"],\n",
    "    template = \"Pergunta: {pergunta}\\nResposta: {resposta}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "708ac528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pergunta: Qual é a maior montanha do mundo, o Monte Everest ou o K2?\\nResposta: \\nSão necessárias perguntas de acompanhamento aqui: Sim.\\nPergunta de acompanhamento: Qual é a altura do Monte Everest?\\nResposta intermediária: O Monte Everest tem 8.848 metros de altura.\\nPergunta de acompanhamento: Qual é a altura do K2?\\nResposta intermediária: O K2 tem 8.611 metros de altura.\\nEntão a resposta final é: Monte Everest\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt.format(**exemplos[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21cd3a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples = exemplos,\n",
    "    example_prompt = example_prompt,\n",
    "    suffix = \"Pergunta: {input}\",\n",
    "    input_variables = [\"input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d08c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: Qual é a maior montanha do mundo, o Monte Everest ou o K2?\n",
      "Resposta: \n",
      "São necessárias perguntas de acompanhamento aqui: Sim.\n",
      "Pergunta de acompanhamento: Qual é a altura do Monte Everest?\n",
      "Resposta intermediária: O Monte Everest tem 8.848 metros de altura.\n",
      "Pergunta de acompanhamento: Qual é a altura do K2?\n",
      "Resposta intermediária: O K2 tem 8.611 metros de altura.\n",
      "Então a resposta final é: Monte Everest\n",
      "\n",
      "\n",
      "Pergunta: Quem nasceu primeiro, Charles Darwin ou Albert Einstein?\n",
      "Resposta: \n",
      "São necessárias perguntas de acompanhamento aqui: Sim.\n",
      "Pergunta de acompanhamento: Quando nasceu Charles Darwin?\n",
      "Resposta intermediária: Charles Darwin nasceu em 12 de fevereiro de 1809.\n",
      "Pergunta de acompanhamento: Quando nasceu Albert Einstein?\n",
      "Resposta intermediária: Albert Einstein nasceu em 14 de março de 1879.\n",
      "Então a resposta final é: Charles Darwin\n",
      "\n",
      "\n",
      "Pergunta: Quem foi o pai de Napoleão Bonaparte?\n",
      "Resposta: \n",
      "São necessárias perguntas de acompanhamento aqui: Sim.\n",
      "Pergunta de acompanhamento: Quem foi Napoleão Bonaparte?\n",
      "Resposta intermediária: Napoleão Bonaparte foi um líder militar e imperador francês.\n",
      "Pergunta de acompanhamento: Quem foi o pai de Napoleão Bonaparte?\n",
      "Resposta intermediária: O pai de Napoleão Bonaparte foi Carlo Bonaparte.\n",
      "Então a resposta final é: Carlo Bonaparte\n",
      "\n",
      "\n",
      "Pergunta: Os filmes 'O Senhor dos Anéis' e 'O Hobbit' foram dirigidos pelo mesmo diretor?\n",
      "Resposta: \n",
      "São necessárias perguntas de acompanhamento aqui: Sim.\n",
      "Pergunta de acompanhamento: Quem dirigiu 'O Senhor dos Anéis'?\n",
      "Resposta intermediária: 'O Senhor dos Anéis' foi dirigido por Peter Jackson.\n",
      "Pergunta de acompanhamento: Quem dirigiu 'O Hobbit'?\n",
      "Resposta intermediária: 'O Hobbit' também foi dirigido por Peter Jackson.\n",
      "Então a resposta final é: Sim\n",
      "\n",
      "\n",
      "Pergunta: Quem é melhor Messi ou Cristiano Ronaldo?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(input=\"Quem é melhor Messi ou Cristiano Ronaldo?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4c744bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nResposta: \\nSão necessárias perguntas de acompanhamento aqui: Sim.\\nPergunta de acompanhamento: Quantos gols Messi fez?\\nResposta intermediária: Messi fez 731 gols em sua carreira profissional até o momento.\\nPergunta de acompanhamento: Quantos gols Cristiano Ronaldo fez?\\nResposta intermediária: Cristiano Ronaldo fez 745 gols em sua carreira profissional até o momento.\\nEntão a resposta final é: Cristiano Ronaldo (745 gols)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt.format(input=\"Quem fez mais gols Messi ou Cristiano Ronaldo?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1f88e2",
   "metadata": {},
   "source": [
    "### Few Shot Prompting em Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f8641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dceb6ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Qual é a maior montanha do mundo, o Monte Everest ou o K2?'), AIMessage(content='\\nSão necessárias perguntas de acompanhamento aqui: Sim.\\nPergunta de acompanhamento: Qual é a altura do Monte Everest?\\nResposta intermediária: O Monte Everest tem 8.848 metros de altura.\\nPergunta de acompanhamento: Qual é a altura do K2?\\nResposta intermediária: O K2 tem 8.611 metros de altura.\\nEntão a resposta final é: Monte Everest\\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{pergunta}\"),\n",
    "        (\"ai\", \"{resposta}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(example_prompt.format_messages(**exemplos[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0aa6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_template = FewShotChatMessagePromptTemplate(\n",
    "    examples=exemplos,\n",
    "    example_prompt=example_prompt\n",
    ")\n",
    "\n",
    "prompt_final = ChatPromptTemplate.from_messages([\n",
    "    few_shot_template,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "prompt = prompt_final.format_messages(input=\"Quem fez mais gols, Messi ou Cristiano Ronaldo?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87ab5de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Até o momento, Cristiano Ronaldo marcou mais gols do que Lionel Messi em suas carreiras. Cristiano Ronaldo é conhecido por sua incrível capacidade de marcar gols e tem tido um desempenho excepcional ao longo dos anos, ultrapassando Messi em número de gols marcados. No entanto, é importante ressaltar que ambos são considerados dois dos maiores jogadores de futebol de todos os tempos e têm tido carreiras impressionantes.', response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 504, 'total_tokens': 612, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-43a5f19f-9e14-4856-acb6-f231b9ea1a0a-0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32820c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
