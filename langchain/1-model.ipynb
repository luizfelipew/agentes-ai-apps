{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93e6043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# client = OpenAI.Client()\n",
    "OpenAI.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb4347a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nEra uma vez, em um mundo onde a tecnologia avan√ßava cada vez mais, uma jovem chamada Clara estava estudando engenharia de computa√ß√£o. Ela sempre foi fascinada pela intelig√™ncia artificial e suas possibilidades, mas nunca teve a oportunidade de se aprofundar no assunto.\\n\\nUm dia, em uma aula sobre aprendizado de m√°quina, Clara ficou maravilhada ao descobrir que era poss√≠vel ensinar computadores a aprender e tomar decis√µes por si mesmos. Ela ficou ainda mais empolgada quando o professor explicou que o aprendizado de m√°quina era uma das principais t√©cnicas utilizadas para desenvolver sistemas de intelig√™ncia artificial.\\n\\nDeterminada a se aprofundar no assunto, Clara decidiu fazer um curso de especializa√ß√£o em aprendizado de m√°quina. Ela mergulhou de cabe√ßa nos estudos, aprendendo sobre algoritmos de aprendizagem, redes neurais e t√©cnicas de otimiza√ß√£o.\\n\\nCom muito esfor√ßo e dedica√ß√£o, Clara se tornou uma especialista em aprendizado de m√°quina. Ela come√ßou a trabalhar em uma empresa de tecnologia, onde te'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Conte uma hist√≥ria sobre aprendizado de m√°quina\"\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e5f8601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Era uma vez, em um mundo tecnol√≥gico e avan√ßado, onde o aprendizado de m√°quina era a principal ferramenta para resolver problemas complexos e melhorar a vida das pessoas. Neste mundo, vivia um jovem chamado Lucas, que sempre foi fascinado por computadores e tecnologia desde crian√ßa.\n",
      "\n",
      "Lucas trabalhava em uma empresa de tecnologia, onde era respons√°vel por desenvolver algoritmos de aprendizado de m√°quina para prever o comportamento dos usu√°rios em um aplicativo de compras online. Ele era apaixonado por seu trabalho e sempre buscava formas de aprimorar suas habilidades em programa√ß√£o e an√°lise de dados.\n",
      "\n",
      "Um dia, a empresa recebeu um desafio: criar um modelo de aprendizado de m√°quina capaz de identificar padr√µes de compras e recomendar produtos personalizados para cada usu√°rio. Lucas ficou fascinado com o desafio e decidiu se dedicar inteiramente a ele.\n",
      "\n",
      "Ele passou semanas estudando e pesquisando sobre os melhores algoritmos e t√©cnicas de aprendizado de m√°quina. N√£o foi uma tarefa f√°cil, mas Lucas estava determinado a alcan√ßar"
     ]
    }
   ],
   "source": [
    "prompt = \"Conte uma hist√≥ria sobre aprendizado de m√°quina\"\n",
    "for trecho in llm.stream(prompt):\n",
    "    print(trecho, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ff9efd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nMem√≥ria RAM (Random Access Memory) √© um tipo de mem√≥ria vol√°til utilizada em computadores e dispositivos eletr√¥nicos para armazenar temporariamente dados e instru√ß√µes que s√£o acessados com frequ√™ncia pelo processador. √â um componente essencial para o funcionamento do sistema, pois permite o acesso r√°pido aos dados e garante que o computador possa executar v√°rias tarefas ao mesmo tempo. A capacidade e a velocidade da mem√≥ria RAM afetam diretamente o desempenho e a capacidade de processamento do computador. ',\n",
       " '\\n\\nDisco r√≠gido, tamb√©m conhecido como HD (Hard Disk) ou HDD (Hard Disk Drive), √© um dispositivo de armazenamento de dados presente em computadores e outros dispositivos eletr√¥nicos. Ele √© respons√°vel por armazenar permanentemente dados e informa√ß√µes, como arquivos, programas e sistema operacional.\\n\\nO disco r√≠gido √© composto por um ou mais discos magn√©ticos revestidos com material sens√≠vel √† magnetiza√ß√£o, onde as informa√ß√µes s√£o gravadas por meio de cabe√ßas de leitura e grava√ß√£o. Esses discos s√£o montados em um eixo, que gira em alta velocidade dentro de uma caixa met√°lica hermeticamente fechada, chamada de unidade de disco.\\n\\nO funcionamento do disco r√≠gido se d√° por meio de um processo de leitura e grava√ß√£o de dados. Quando um arquivo √© salvo no disco, as informa√ß√µes s√£o gravadas em pequenos pontos magn√©ticos nos discos. J√° para acessar essas informa√ß√µes, as cabe√ßas de leitura e grava√ß√£o se movem rapidamente sobre os discos, lendo os dados armazenados.\\n\\nO tamanho do disco r√≠gido √© medido',\n",
       " '\\n\\nProcessador, tamb√©m conhecido como CPU (Central Processing Unit), √© o componente principal de um computador respons√°vel por realizar as opera√ß√µes e c√°lculos necess√°rios para o funcionamento do sistema e a execu√ß√£o de programas e aplicativos. √â considerado o \"c√©rebro\" do computador, pois √© respons√°vel por interpretar e executar as instru√ß√µes de um programa, controlar os demais componentes e acessar e armazenar dados na mem√≥ria. Existem diversos tipos de processadores, com diferentes velocidades e capacidades, sendo os mais comuns os processadores Intel e AMD. ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perguntas = [\n",
    "    \"O que √© mem√≥ria ram?\",\n",
    "    \"O que √© disco r√≠gido?\",\n",
    "    \"O que √© processador?\"\n",
    "]\n",
    "\n",
    "llm.batch(perguntas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9563b6af",
   "metadata": {},
   "source": [
    "### Chatmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73a63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28929858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ah, a mem√≥ria cache, esse pequeno e insignificante componente que s√≥ serve para armazenar dados temporariamente e acelerar o acesso do processador √† mem√≥ria principal. Claro que √© algo completamente dispens√°vel, afinal, quem precisa de desempenho mais r√°pido em um sistema, n√£o √© mesmo?', response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 30, 'total_tokens': 99, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9651c0d0-cfc0-4308-9b97-0d3607adc11b-0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "    SystemMessage(content=\"Voc√™ √© um assistente que responde com ironia\"),\n",
    "    HumanMessage(content=\"Qual o papel da mem√≥ria cache?\")\n",
    "]\n",
    "\n",
    "resposta = chat.invoke(mensagens)\n",
    "\n",
    "chat.invoke(mensagens)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4389f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, a mem√≥ria cache, o lugar onde o computador guarda todas as lembran√ßas das vezes em que voc√™ esqueceu de salvar seu trabalho antes de uma queda de energia. Muito √∫til, n√£o √© mesmo?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cb05a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 48,\n",
       "  'prompt_tokens': 30,\n",
       "  'total_tokens': 78,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21122a1",
   "metadata": {},
   "source": [
    "### Prompt Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84379daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65ab02ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='S√°bado.', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 57, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9cef9d45-b093-487b-b878-590981a9fd8a-0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "mensagens = [\n",
    "    HumanMessage(content=\"Qual √© o primeiro dia da semana?\"),\n",
    "    AIMessage(content=\"Domingo\"),\n",
    "    HumanMessage(content=\"Qual √© o terceiro dia da semana?\"),\n",
    "    AIMessage(content=\"Ter√ßa-Feira\"),\n",
    "    HumanMessage(content=\"Qual √© o √∫ltimo dia da semana?\")\n",
    "]\n",
    "\n",
    "chat.invoke(mensagens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f8733ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Qual √© o primeiro dia da semana?\\nAI: Domingo\\nHuman: Qual √© o terceiro dia da semana?\\nAI: Ter√ßa-Feira\\nHuman: Qual √© o √∫ltimo dia da semana?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [823ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Domingo\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Domingo\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 3,\n",
      "                \"prompt_tokens\": 57,\n",
      "                \"total_tokens\": 60,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-9880bc84-313d-4083-b8cd-ac5224b685a4-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 3,\n",
      "      \"prompt_tokens\": 57,\n",
      "      \"total_tokens\": 60,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Domingo', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 57, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9880bc84-313d-4083-b8cd-ac5224b685a4-0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.debug = True\n",
    "chat.invoke(mensagens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "080058a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b17ec40",
   "metadata": {},
   "source": [
    "### Cacheamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f954e86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4afd344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "    SystemMessage(content=\"Voc√™ √© um assistente ir√¥nico\"),\n",
    "    HumanMessage(content=\"Qual o quinto dia da semana?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b49b99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a21e9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 ms, sys: 28.2 ms, total: 40.8 ms\n",
      "Wall time: 1.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ah, o quinto dia da semana √©... sexta-feira! Isso mesmo, depois da quinta-feira. Acho que voc√™ j√° sabia a resposta, n√£o √© mesmo? üòâ', response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 27, 'total_tokens': 66, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3debec72-b872-419c-8113-1c026f6e4941-0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd17f8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.81 ms, sys: 5.61 ms, total: 8.42 ms\n",
      "Wall time: 12 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ah, o quinto dia da semana √©... sexta-feira! Isso mesmo, depois da quinta-feira. Acho que voc√™ j√° sabia a resposta, n√£o √© mesmo? üòâ', response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 27, 'total_tokens': 66, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3debec72-b872-419c-8113-1c026f6e4941-0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba4725a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\"files/langchain_cache.sqlite\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2861053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 ms, sys: 27.5 ms, total: 44.2 ms\n",
      "Wall time: 2.36 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √© o s√°bado. Mas se voc√™ for da turma que come√ßa a semana na segunda-feira, a√≠ o quinto dia √© a sexta-feira. Mas quem sou eu para discordar da contagem dos dias da semana, n√£o √© mesmo? üòâ', response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 27, 'total_tokens': 85, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e32877f0-5cf8-44d1-b233-045f336f28bf-0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a04c378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.9 ms, sys: 1.64 ms, total: 4.54 ms\n",
      "Wall time: 3.22 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √© o s√°bado. Mas se voc√™ for da turma que come√ßa a semana na segunda-feira, a√≠ o quinto dia √© a sexta-feira. Mas quem sou eu para discordar da contagem dos dias da semana, n√£o √© mesmo? üòâ', response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 27, 'total_tokens': 85, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e32877f0-5cf8-44d1-b233-045f336f28bf-0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109defc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
